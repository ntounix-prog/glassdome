# Glassdome Logstash Pipeline
# ============================
# Processes logs from all Glassdome components:
# - Backend API
# - Orchestrator
# - Reapers (vulnerability injection)
# - WhiteKnights (validation)
# - WhitePawns (monitoring)
# - Overseer (AI agent)
#
# Author: Brett Turner (ntounix)
# Created: December 2025

# ============================================================================
# INPUT SECTION
# ============================================================================

input {
  # Beats input (from Filebeat)
  beats {
    port => 5044
    host => "0.0.0.0"
    tags => ["beats", "glassdome"]
  }
  
  # JSON/TCP input (direct from Python logging)
  tcp {
    port => 5045
    host => "0.0.0.0"
    codec => json_lines
    tags => ["tcp", "glassdome", "python"]
  }
  
  # HTTP input (for webhooks/REST API logging)
  http {
    port => 5046
    host => "0.0.0.0"
    codec => json
    tags => ["http", "glassdome", "webhook"]
  }
  
  # Syslog input (from infrastructure)
  syslog {
    port => 5514
    type => "syslog"
    tags => ["syslog", "infrastructure"]
  }
}

# ============================================================================
# FILTER SECTION
# ============================================================================

filter {
  # Process Glassdome JSON logs
  if "glassdome" in [tags] or [application] == "glassdome" {
    
    # Parse timestamp if present
    if [timestamp] {
      date {
        match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ", "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"]
        target => "@timestamp"
        remove_field => ["timestamp"]
      }
    }
    
    # Normalize log level
    if [level] {
      mutate {
        uppercase => ["level"]
      }
    }
    
    # Extract component from logger name (e.g., glassdome.api.labs -> api.labs)
    if [logger] {
      mutate {
        gsub => ["logger", "^glassdome\.", ""]
      }
      
      # Extract top-level component
      grok {
        match => { "logger" => "^%{WORD:component}" }
        tag_on_failure => []
      }
    }
    
    # Parse worker ID from message or existing field
    if [worker_id] {
      mutate {
        add_field => { "worker" => "%{worker_id}" }
      }
    }
    
    # Extract request context
    if [request_id] {
      mutate {
        add_field => { "trace_id" => "%{request_id}" }
      }
    }
    
    # Categorize by log type
    if [component] == "api" {
      mutate { add_field => { "category" => "api" } }
    } else if [component] == "reaper" {
      mutate { add_field => { "category" => "vulnerability" } }
    } else if [component] == "whiteknight" {
      mutate { add_field => { "category" => "validation" } }
    } else if [component] == "whitepawn" {
      mutate { add_field => { "category" => "monitoring" } }
    } else if [component] == "orchestration" or [component] == "orchestrator" {
      mutate { add_field => { "category" => "deployment" } }
    } else if [component] == "overseer" or [component] == "chat" {
      mutate { add_field => { "category" => "ai" } }
    } else if [component] == "platforms" or [component] == "proxmox" {
      mutate { add_field => { "category" => "infrastructure" } }
    } else {
      mutate { add_field => { "category" => "general" } }
    }
    
    # Parse exception stack traces
    if [exception] {
      mutate {
        add_field => { "has_exception" => true }
      }
      
      # Extract exception class from first line
      grok {
        match => { "exception" => "^%{WORD:exception_type}:" }
        tag_on_failure => []
      }
    }
    
    # GeoIP lookup for IP addresses (if present)
    if [client_ip] {
      geoip {
        source => "client_ip"
        target => "geoip"
        tag_on_failure => []
      }
    }
    
    # Add metadata
    mutate {
      add_field => {
        "[@metadata][index_prefix]" => "glassdome"
        "application" => "glassdome"
      }
    }
  }
  
  # Process syslog messages
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_host} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => { "[@metadata][index_prefix]" => "infrastructure" }
      tag_on_failure => ["_grokparsefailure_syslog"]
    }
    
    date {
      match => ["syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss"]
      target => "@timestamp"
    }
    
    mutate {
      remove_field => ["syslog_timestamp"]
    }
  }
  
  # Add common fields
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:lab}"
      "cluster" => "glassdome-lab"
    }
  }
  
  # Remove redundant fields
  mutate {
    remove_field => ["@version", "host.name", "agent.ephemeral_id"]
  }
}

# ============================================================================
# OUTPUT SECTION
# ============================================================================

output {
  # Elasticsearch output
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    
    # Dynamic index based on type
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
    
    # Index template settings
    template_name => "glassdome"
    template_overwrite => true
    
    # Retry settings
    retry_on_conflict => 3
  }
  
  # Console output for debugging (disable in production)
  # stdout {
  #   codec => rubydebug
  # }
  
  # File output for backup/audit (optional)
  # file {
  #   path => "/var/log/logstash/glassdome-%{+YYYY-MM-dd}.log"
  #   codec => json_lines
  # }
}

